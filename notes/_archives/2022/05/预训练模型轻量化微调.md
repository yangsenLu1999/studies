预训练模型的轻量化微调
===
<!--START_SECTION:badge-->

![last modify](https://img.shields.io/static/v1?label=last%20modify&message=2022-10-13%2001%3A56%3A19&color=yellowgreen&style=flat-square)

<!--END_SECTION:badge-->

- [背景](#背景)
    - [三种解决思路](#三种解决思路)
- [轻量化微调（Lightweight Finetuning）](#轻量化微调lightweight-finetuning)
    - [Adapter](#adapter)
    - [LoRA](#lora)
    - [Prefix-Tuning](#prefix-tuning)
    - [其他论文](#其他论文)
- [参考](#参考)

## 背景
> [从遗忘问题到预训练轻量化微调 - 李rumor](https://mp.weixin.qq.com/s/C_6qlTq63IBnRSEMnDO7SQ)

- “**预训练+微调**”范式有效的前提是，我们假设模型在海量数据上学到了大量**先验知识**，而这些知识被存储在模型的**参数**中；
- 对整个预训练模型进行微调，意味着会**改动**这些参数；如果变动太大，那么就可能会带来“**灾难性遗忘**”的问题；
    - 一个简单的验证方法：“有的时候，大家可以试试学习率大一些跑跑，会发现学几代以后loss就会骤变，这个其实就是重现遗忘最简单的方式。”
    - 不过参数变动不代表知识一定会丢失，大多数情况下，“预训练+微调”依然是有效的；


### 三种解决思路

1. **Replay**: 重播，就是在新任务中，把老的内容复习一遍，能让模型保留住。
    - 虽然实现简单，但是现在的预训练模型和数据都很“重”，成本很大；
2. **Regularization-Based**: 在损失函数上应用正则化方法，使新模型和原模型之间的差距不会很大（跟蒸馏的思想很接近）
    - 实现简单，对模型的改动很小；
    - 这个方法有两个问题：1）需要微调整个模型，效率低；2）可能会导致**训练目标的偏移**，即得到的不是最优解；
3. **Lightweight Finetuning**: 轻量化微调，目前比较常见的方法是**参数孤立化**（Parameter Isolation），即冻住预训练模型，加入新的模块，只微调该模块来避免遗忘的问题。
    - 目前比较主流的方法，兼顾了“遗忘问题”和训练效率；


## 轻量化微调（Lightweight Finetuning）

- 目前**轻量化微调**的主要方法是**参数孤立化**，即不动预训练模型，而是在预训练模型的基础上增加新的可训练参数
    > **关键词**：`Parameter Isolation`、 `Parameter-Efficient`
- 下面介绍三种常见的**参数孤立化**方法；

### Adapter
> [[1902.00751] Parameter-Efficient Transfer Learning for NLP](https://arxiv.org/abs/1902.00751)


### LoRA
> [[2106.09685] LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685)


### Prefix-Tuning
> [[2101.00190] Prefix-Tuning: Optimizing Continuous Prompts for Generation](https://arxiv.org/abs/2101.00190)


### 其他论文

- [[2110.04366] Towards a Unified View of Parameter-Efficient Transfer Learning](https://arxiv.org/abs/2110.04366)
    - 对以上三种方法进行了总结，


## 参考
- A continual learning survey: Defying forgetting in classification tasks
    > 从 NLP 领域出发，介绍遗忘存在的本质，并综述了一些比较常见的解决方案